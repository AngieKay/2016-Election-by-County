{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "pd.set_option(\"max_columns\", None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "df = pd.read_csv('poverty.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns = df.iloc[0]\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.drop(df.index[0], inplace = True)\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "Remove columns that contain the word 'Bound'. These are not needed.\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.contains('Bound')]\n",
    "\n",
    "Remove columns that are percentages.\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.contains('Percent')]\n",
    "\n",
    "Locate DC and change County FIPS so it isn't dropped during the next step.\n",
    "\n",
    "df.loc[(df['County FIPS'] == '000') & (df['Name'] == 'District of Columbia')]\n",
    "\n",
    "df.iloc[327:330, :]\n",
    "\n",
    "Nevermind. DC is in there alone and summed (as if it was a state). Just drop all County FIPS 000.\n",
    "\n",
    "Drop all rows with county FIPS 000. These are just states summed. We don't need them. Might be useful to look at for any missing information later though.\n",
    "\n",
    "drop = df.loc[(df['County FIPS'] == '000')]\n",
    "\n",
    "df = df.drop(drop.index, axis = 0)\n",
    "\n",
    "Check on the Hawaii counties. May need to drop Kalawao (no election results. Very low pop) Change states to full words. Look for Puerto Rico. Strip county, borough, etc. \n",
    "\n",
    "df.loc[(df['Postal'] == 'HI')]\n",
    "\n",
    "Kalawao = (pd.DataFrame(df.loc[562]))\n",
    "df = df.drop(Kalawao)\n",
    "\n",
    "df.head()\n",
    "\n",
    "us_state_abbrev = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming',\n",
    "}\n",
    "\n",
    "df.Postal = df.Postal.map(us_state_abbrev)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df = df.drop(df.iloc[:, [0, 1, 6, 8]], axis = 1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df['Name'] = df['Name'].str.replace('(Borough|County|Area|Census|Municipality|and|City|Municipali)', '')\n",
    "\n",
    "Chugach and Copper River are already combined into Valdez-Cordova so no need to change that. Renaming Wade Hampton to Kusilvak to match results.\n",
    "\n",
    "df.loc[df['Postal'] == 'Alaska']\n",
    "\n",
    "df.loc[96]['Name'] = 'Kusilvak'\n",
    "\n",
    "Remove punctuation.\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    try:\n",
    "        x = x.str.replace('[^\\w\\s]','')\n",
    "    except:\n",
    "        pass\n",
    "    return x\n",
    "df = df.apply(remove_punctuation)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns = ['state', 'county', 'poverty_total', 'poverty_under_18', 'median_household_income']\n",
    "\n",
    "df = df.sort_values(by = ['state', 'county']).reset_index(drop = True)\n",
    "\n",
    "df.info()\n",
    "\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype(float)\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "race = load(open('results_race_with_alaska.pkl', 'rb'))\n",
    "\n",
    "df.loc[~df['county'].isin(race['County'])]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
